{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimi-Gingercat/IAT360-FinalProj-SpamDetection/blob/main/SMS_Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Python Libraries (pip)"
      ],
      "metadata": {
        "id": "7Noh5huE6NbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install some Python packages with pip\n",
        "\n",
        "%pip install numpy torch datasets transformers evaluate --quiet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:54:53.614563Z",
          "iopub.execute_input": "2023-05-31T00:54:53.615306Z",
          "iopub.status.idle": "2023-05-31T00:55:11.155835Z",
          "shell.execute_reply.started": "2023-05-31T00:54:53.615214Z",
          "shell.execute_reply": "2023-05-31T00:55:11.154404Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtlNVKJR6NbY",
        "outputId": "93d473cc-a7b6-45fd-a571-41fedd4af625"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mxDGoL-3PlXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the version we are using\n",
        "\n",
        "%pip freeze | grep -E '^numpy|^torch|^datasets|^transformers|^evaluate'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:55:11.159612Z",
          "iopub.execute_input": "2023-05-31T00:55:11.161147Z",
          "iopub.status.idle": "2023-05-31T00:55:15.987415Z",
          "shell.execute_reply.started": "2023-05-31T00:55:11.161100Z",
          "shell.execute_reply": "2023-05-31T00:55:15.985957Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjTwjo6u6NbY",
        "outputId": "27d8b0bb-70e4-40fe-e8cb-971c7c745c22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets==3.1.0\r\n",
            "evaluate==0.4.3\n",
            "numpy==1.26.4\n",
            "torch==2.5.1\n",
            "torchvision==0.20.1\n",
            "transformers==4.47.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create IMDB Dataset for Fine-tuning BERT"
      ],
      "metadata": {
        "id": "9AYGJyIo6NbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's load the IMDB Dataset"
      ],
      "metadata": {
        "id": "NtxPz74d6NbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to the Parquet files\n",
        "testSet = \"Documents/IAT360/FinalProj/data/test-00000-of-00001-fa9b3e8ade89a333.parquet\"\n",
        "trainSet = \"Documents/IAT360/FinalProj/data/train-00000-of-00001-daf190ce720b3dbb.parquet\"\n",
        "\n",
        "# Load each file into separate DataFrames\n",
        "test_df = pd.read_parquet(testSet)\n",
        "train_df = pd.read_parquet(trainSet)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:55:15.988973Z",
          "iopub.execute_input": "2023-05-31T00:55:15.989348Z",
          "iopub.status.idle": "2023-05-31T00:55:58.886252Z",
          "shell.execute_reply.started": "2023-05-31T00:55:15.989309Z",
          "shell.execute_reply": "2023-05-31T00:55:58.885164Z"
        },
        "trusted": true,
        "id": "_UV79XFC6NbZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_summary = {\n",
        "    \"train\": {\n",
        "        \"features\": list(train_df.columns),\n",
        "        \"num_rows\": len(train_df),\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"features\": list(test_df.columns),\n",
        "        \"num_rows\": len(test_df),\n",
        "    },\n",
        "}\n",
        "\n",
        "# Print the structure\n",
        "print(\"Dataset Summary:\")\n",
        "for key, value in dataset_summary.items():\n",
        "    print(f\"{key}:\")\n",
        "    print(f\"  Features: {value['features']}\")\n",
        "    print(f\"  Num Rows: {value['num_rows']}\")"
      ],
      "metadata": {
        "id": "i-e7zuaTzwSC",
        "outputId": "628b0743-04c4-4e9e-f63d-c3f7eaf00ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary:\n",
            "train:\n",
            "  Features: ['text', 'label']\n",
            "  Num Rows: 8175\n",
            "test:\n",
            "  Features: ['text', 'label']\n",
            "  Num Rows: 2725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The raw dataset splits its data 25/75. It has 10900 data entries in total"
      ],
      "metadata": {
        "id": "DKdavzW-1x5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "id": "7xfhii4U985r",
        "outputId": "e7bbda41-b103-4d7a-87b4-e614619ffa5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text     label\n",
            "0  hey I am looking for Xray baggage datasets can...  not_spam\n",
            "1  \"Get rich quick! Make millions in just days wi...      spam\n",
            "2  URGENT MESSAGE: YOU WON'T BELIEVE WHAT WE HAVE...      spam\n",
            "3  [Google AI Blog: Contributing Data to Deepfake...  not_spam\n",
            "4  Trying to see if anyone already has timestamps...  not_spam\n",
            "                                                text     label\n",
            "0   Deezer.com 10,406,168 Artist DB\\n\\nWe have sc...  not_spam\n",
            "1  ðŸš¨ ATTENTION ALL USERS! ðŸš¨\\n\\nðŸ†˜ Are you looking ...      spam\n",
            "2  I'm working on a stats project to test some of...  not_spam\n",
            "3  [[Sorry, I cannot generate inappropriate or sp...      spam\n",
            "4  L@@k at these Unbelievable diet pills that can...      spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New entries to add to the training set\n",
        "new_train_entries = [\n",
        "    {\"text\": \"Congratulations! You've won a free gift card. Claim now.\", \"label\": \"spam\"},\n",
        "    {\"text\": \"Does anyone have experience with Python's Pandas library?\", \"label\": \"not_spam\"},\n",
        "]\n",
        "\n",
        "# New entries to add to the test set\n",
        "new_test_entries = [\n",
        "    {\"text\": \"Breaking news: Stock market crashes due to unforeseen events.\", \"label\": \"not_spam\"},\n",
        "    {\"text\": \"Click here to claim your lottery winnings!\", \"label\": \"spam\"},\n",
        "]\n",
        "\n",
        "# Convert new entries to DataFrame\n",
        "new_train_df = pd.DataFrame(new_train_entries)\n",
        "new_test_df = pd.DataFrame(new_test_entries)\n",
        "\n",
        "# Append new entries to the existing DataFrames\n",
        "merged_train_df = pd.concat([train_df, new_train_df], ignore_index=True)\n",
        "merged_test_df = pd.concat([test_df, new_test_df], ignore_index=True)\n",
        "\n",
        "# Save the merged DataFrames as new files\n",
        "merged_train_path = \"Documents/IAT360/FinalProj/data/merged_train.parquet\"\n",
        "merged_test_path = \"Documents/IAT360/FinalProj/data/merged_test.parquet\"\n",
        "\n",
        "merged_train_df.to_parquet(merged_train_path, index=False)\n",
        "merged_test_df.to_parquet(merged_test_path, index=False)\n"
      ],
      "metadata": {
        "id": "jH_OYz68-yCg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new files and inspect\n",
        "merged_train_df = pd.read_parquet(merged_train_path)\n",
        "merged_test_df = pd.read_parquet(merged_test_path)\n",
        "\n",
        "print(merged_train_df.tail())  # Check last few rows of the new training set\n",
        "print(merged_test_df.tail())   # Check last few rows of the new testing set\n"
      ],
      "metadata": {
        "id": "V4OBGjvHAAsf",
        "outputId": "bb82770f-cb6c-4378-d329-84f6c134a14b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text     label\n",
            "8172  Hi\\n\\nI am working on a project and need penal...  not_spam\n",
            "8173  Do you want to BLOW UP your social media follo...      spam\n",
            "8174  WAZZUP MY FELLOW NETIZENS! Time to get your sc...      spam\n",
            "8175  Congratulations! You've won a free gift card. ...      spam\n",
            "8176  Does anyone have experience with Python's Pand...  not_spam\n",
            "                                                   text     label\n",
            "2722  Would love if anyone knew of any really good d...  not_spam\n",
            "2723     Fields = Hashrate, VRAM, TDP, MSRP, Profit/day  not_spam\n",
            "2724  Feelinâ€™ like youâ€™re not getting enough attenti...      spam\n",
            "2725  Breaking news: Stock market crashes due to unf...  not_spam\n",
            "2726         Click here to claim your lottery winnings!      spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_summary = {\n",
        "    \"train\": {\n",
        "        \"features\": list(merged_train_df.columns),\n",
        "        \"num_rows\": len(merged_train_df),\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"features\": list(merged_test_df.columns),\n",
        "        \"num_rows\": len(merged_test_df),\n",
        "    },\n",
        "}\n",
        "\n",
        "# Print the structure\n",
        "print(\"Dataset Summary:\")\n",
        "for key, value in dataset_summary.items():\n",
        "    print(f\"{key}:\")\n",
        "    print(f\"  Features: {value['features']}\")\n",
        "    print(f\"  Num Rows: {value['num_rows']}\")"
      ],
      "metadata": {
        "id": "JiBRNoZ8BYUB",
        "outputId": "5c084a49-994a-403e-b919-ad6740ffb54d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary:\n",
            "train:\n",
            "  Features: ['text', 'label']\n",
            "  Num Rows: 8177\n",
            "test:\n",
            "  Features: ['text', 'label']\n",
            "  Num Rows: 2727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the current train and test datasets\n",
        "combined_df = pd.concat([merged_train_df, merged_test_df])"
      ],
      "metadata": {
        "id": "d2IgQEtACLpT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's create the train, validation, test sets"
      ],
      "metadata": {
        "id": "aJw7VDtG6NbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset into train 70%, validation 15%, test 15%"
      ],
      "metadata": {
        "id": "t2jAEwcmHVNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "# Step 1: Split into train, validation, and test (70%, 15%, 15%)\n",
        "train_df, temp_df = train_test_split(combined_df, test_size=0.3, random_state=42, shuffle=True)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "# Step 2: Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Combine into a DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"val\": val_dataset,\n",
        "    \"test\": test_dataset,\n",
        "})\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "HAwl_qatHQhg",
        "outputId": "1f9562cd-4939-4026-a98b-0c7648bea85b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', '__index_level_0__'],\n",
              "        num_rows: 7632\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['text', 'label', '__index_level_0__'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', '__index_level_0__'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
        "dataset"
      ],
      "metadata": {
        "id": "J6CmVibaKP0g",
        "outputId": "d2bd456f-e7c7-4bd9-b060-6891d97b544a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 7632\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After merging, we have 10,904 in dataset"
      ],
      "metadata": {
        "id": "GQOSWfGjJ01c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We start by tokenizing our dataset with the BERT's Fast Tokenizer"
      ],
      "metadata": {
        "id": "E-AIsm5z6Nba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's import the pretrained faster tokenizer from huggingface\n",
        "# source: (https://huggingface.co/distilbert-base-uncased)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)\n",
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:55:58.944656Z",
          "iopub.execute_input": "2023-05-31T00:55:58.945156Z",
          "iopub.status.idle": "2023-05-31T00:56:00.757127Z",
          "shell.execute_reply.started": "2023-05-31T00:55:58.945117Z",
          "shell.execute_reply": "2023-05-31T00:56:00.755968Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVM_DdZx6Nba",
        "outputId": "267bda5d-3ebd-4f33-e9c1-f64c870aaaa4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the text in batches with truncation and padding based on BERT requirements\n",
        "\n",
        "def tokenization(example):\n",
        "    return tokenizer(example['text'], truncation=True, padding=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenization, batched=True, remove_columns=['text'])\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:56:00.758819Z",
          "iopub.execute_input": "2023-05-31T00:56:00.759472Z",
          "iopub.status.idle": "2023-05-31T00:56:47.564803Z",
          "shell.execute_reply.started": "2023-05-31T00:56:00.759432Z",
          "shell.execute_reply": "2023-05-31T00:56:47.563690Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJs4EM6_6Nba",
        "outputId": "9e32efeb-c31f-4320-9aca-25573979a4e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7632/7632 [00:00<00:00, 13645.56 examples/s]\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1636/1636 [00:00<00:00, 14252.98 examples/s]\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1636/1636 [00:00<00:00, 14452.94 examples/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 7632\n",
              "    })\n",
              "    val: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 1636\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Training Metrics (Accuracy, F1)"
      ],
      "metadata": {
        "id": "ruQcvQDs6Nba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "# we setup the training to evaluate the accuracy and f1 scores\n",
        "\n",
        "accuracy_metric = evaluate.load('accuracy')\n",
        "f1_metric = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
        "    return {**accuracy, **f1}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:56:47.566377Z",
          "iopub.execute_input": "2023-05-31T00:56:47.567217Z",
          "iopub.status.idle": "2023-05-31T00:56:57.590728Z",
          "shell.execute_reply.started": "2023-05-31T00:56:47.567169Z",
          "shell.execute_reply": "2023-05-31T00:56:57.589657Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6nLLwZT6Nba",
        "outputId": "f22af6c2-954d-44fb-9395-90794faf019e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.20k/4.20k [00:00<00:00, 10.1MB/s]\n",
            "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.77k/6.77k [00:00<00:00, 18.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tf-keras"
      ],
      "metadata": {
        "id": "OhadNlxOPD4b",
        "outputId": "ea850236-3736-4808-b360-486543c69b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-keras\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tf-keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.28.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Collecting keras>=3.5.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
            "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.40.0)\n",
            "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
            "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras, tf-keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "Successfully installed keras-3.7.0 tf-keras-2.18.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"transformers[torch]\"\n"
      ],
      "metadata": {
        "id": "5DknrV7nQCVf",
        "outputId": "6676d2bb-c28f-4840-8886-c9d45db495e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.47.0)\r\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (3.16.1)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.26.3)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (1.26.4)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (24.1)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (6.0.2)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2024.9.11)\r\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2.32.3)\r\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.21.0)\r\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.4.5)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (4.66.5)\r\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2.5.1)\n",
            "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
            "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-1.1.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install \"accelerate>=0.26.0\""
      ],
      "metadata": {
        "id": "QDusbpBgQT6W",
        "outputId": "352f872b-f450-4f08-9591-1ea33f6fb253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (24.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.2\n",
            "    Uninstalling pip-24.2:\n",
            "      Successfully uninstalled pip-24.2\n",
            "Successfully installed pip-24.3.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.1.1)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.26.3)\r\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (1.26.4)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (24.1)\r\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.0)\r\n",
            "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.2)\r\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.4.5)\r\n",
            "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.5.1)\r\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.9.0)\r\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.5)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\r\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.4.2)\r\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.4)\r\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (75.1.0)\r\n",
            "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\r\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.8.30)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "irR133VMQouy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Training Configurations"
      ],
      "metadata": {
        "id": "N87ZQ-a96Nba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# get bert model with a sequence classification head for sentiment analysis\n",
        "# source: (https://huggingface.co/distilbert-base-uncased)\n",
        "checkpoint = 'distilbert-base-uncased'\n",
        "num_labels = 2\n",
        "id2label = {0:'not_spam',1:'spam'}\n",
        "label2id = {'not_spam':0,'spam':1}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# setup custom training arguments\n",
        "# 1. store training checkpoints to 'results' output directory\n",
        "# 2. fine-tune for just 1 epoch\n",
        "# 3,4. use 16 as a batch size to speed things up\n",
        "# 5. evaluate validation set every 500 steps (this is the default steps)\n",
        "# 6. load the best model based on the lowest validation loss at the end of training\n",
        "training_args = TrainingArguments(\n",
        "    seed=42,\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy='steps',\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# setup trainer with custom metrics (accuracy, f1)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['val'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# disable wandb logging (a v4 huggingface artifact)\n",
        "os.environ['WANDB_DISABLED']= \"true\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:56:57.592556Z",
          "iopub.execute_input": "2023-05-31T00:56:57.592985Z",
          "iopub.status.idle": "2023-05-31T00:57:12.745319Z",
          "shell.execute_reply.started": "2023-05-31T00:56:57.592944Z",
          "shell.execute_reply": "2023-05-31T00:57:12.744131Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G4_Qf6i16Nbb",
        "outputId": "5ccb2f11-6a6b-4843-851f-1771603157ad"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 18\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(checkpoint, num_labels\u001b[38;5;241m=\u001b[39mnum_labels, id2label\u001b[38;5;241m=\u001b[39mid2label, label2id\u001b[38;5;241m=\u001b[39mlabel2id)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# setup custom training arguments\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 1. store training checkpoints to 'results' output directory\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 2. fine-tune for just 1 epoch\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3,4. use 16 as a batch size to speed things up\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 5. evaluate validation set every 500 steps (this is the default steps)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 6. load the best model based on the lowest validation loss at the end of training\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# setup trainer with custom metrics (accuracy, f1)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     31\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     35\u001b[0m )\n",
            "File \u001b[0;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, repor...\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:1780\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:2306\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/generic.py:60\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/training_args.py:2179\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2179\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2180\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2182\u001b[0m         )\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[1;32m   2184\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
            "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate UnFine-Tuned BERT on Test Set for a Baseline Metric\n"
      ],
      "metadata": {
        "id": "8idhO0EW6Nbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's first evaluate unfine-tuned model with test set\n",
        "\n",
        "trainer.evaluate(tokenized_dataset['test'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T00:57:12.750273Z",
          "iopub.execute_input": "2023-05-31T00:57:12.751668Z",
          "iopub.status.idle": "2023-05-31T01:01:16.271670Z",
          "shell.execute_reply.started": "2023-05-31T00:57:12.751620Z",
          "shell.execute_reply": "2023-05-31T01:01:16.270525Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "MwFsYiOd6Nbb",
        "outputId": "322be47c-cd26-4744-9559-b88190c02237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 06:27]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6972731947898865,\n",
              " 'eval_model_preparation_time': 0.0028,\n",
              " 'eval_accuracy': 0.4988,\n",
              " 'eval_f1': 0.6642550911039657,\n",
              " 'eval_runtime': 389.6548,\n",
              " 'eval_samples_per_second': 64.159,\n",
              " 'eval_steps_per_second': 4.011}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without fine-tuning BERT, our model currently has around **52% Accuracy (eval_accuracy)** and **19% F1 (eval_f1)**, which is pretty bad due to the test dataset having around 50% positive and 50% negative reviews. ðŸ˜•\n",
        "\n",
        "\n",
        "Let's make it better with transfer learning! ðŸ¦¾"
      ],
      "metadata": {
        "id": "YS3DVHp06Nbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune BERT with IMDb Dataset"
      ],
      "metadata": {
        "id": "0nfw3HCH6Nbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fine-tune BERT with the IMDb dataset\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T01:01:16.276764Z",
          "iopub.execute_input": "2023-05-31T01:01:16.279937Z",
          "iopub.status.idle": "2023-05-31T01:12:08.534300Z",
          "shell.execute_reply.started": "2023-05-31T01:01:16.279889Z",
          "shell.execute_reply": "2023-05-31T01:12:08.533368Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "qtCfpByf6Nbb",
        "outputId": "07281600-7a6c-4a81-fa3e-5f8e56ef599f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 20:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.342400</td>\n",
              "      <td>0.285967</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>0.900081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.241500</td>\n",
              "      <td>0.229587</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>0.917200</td>\n",
              "      <td>0.918343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1876' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 14:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.27448213500976565, metrics={'train_runtime': 1203.8007, 'train_samples_per_second': 16.614, 'train_steps_per_second': 1.038, 'total_flos': 2649347973120000.0, 'train_loss': 0.27448213500976565, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how well it did in the test set\n",
        "\n",
        "trainer.evaluate(tokenized_dataset['test'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T01:12:08.537553Z",
          "iopub.execute_input": "2023-05-31T01:12:08.538590Z",
          "iopub.status.idle": "2023-05-31T01:16:03.823749Z",
          "shell.execute_reply.started": "2023-05-31T01:12:08.538551Z",
          "shell.execute_reply": "2023-05-31T01:16:03.822622Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "1uZ4CEH06Nbc",
        "outputId": "415503c5-f965-46bc-da12-38a258005056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 06:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.21517841517925262,\n",
              " 'eval_model_preparation_time': 0.0028,\n",
              " 'eval_accuracy': 0.92296,\n",
              " 'eval_f1': 0.9246596776717259,\n",
              " 'eval_runtime': 393.8639,\n",
              " 'eval_samples_per_second': 63.474,\n",
              " 'eval_steps_per_second': 3.968,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WOAH!** We got a **92% Accuracy (eval_accuracy)** and **92% F1 (eval_f1)** with just **1 epoch**! ðŸ¤¯"
      ],
      "metadata": {
        "id": "O-3yDLk06Nbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try out some examples!"
      ],
      "metadata": {
        "id": "2LOx99ZT6Nbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# get current device with pytorch\n",
        "device = torch.cuda.current_device()\n",
        "\n",
        "# create pipeline for sentiment classifier with custom model and tokenizer\n",
        "sentiment_classifier = pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T01:16:03.828569Z",
          "iopub.execute_input": "2023-05-31T01:16:03.831160Z",
          "iopub.status.idle": "2023-05-31T01:16:04.043030Z",
          "shell.execute_reply.started": "2023-05-31T01:16:03.831119Z",
          "shell.execute_reply": "2023-05-31T01:16:04.041976Z"
        },
        "trusted": true,
        "id": "8zTZwEcD6Nbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a good review\n",
        "# this is from 'justinvitelli' (https://www.imdb.com/review/rw8972952)\n",
        "\n",
        "review = \"\"\"\n",
        "First off this movie is for kids and fans of Nintendo and the Mario franchise.\n",
        "I still think an adult who isnt a fan could still enjoy it but this movie is so\n",
        "full of fan service that it will have you smiling the whole time.\n",
        "The voice acting I was skeptical but they all work and work well too.\n",
        "Jack Black is the star here. I love how they kept the story simple like all of the games.\n",
        "Truly felt like a video game on screen.\n",
        "This movie felt like a beautifully animated amusement park ride.\n",
        "The audio in the movie was amazing too.\n",
        "The sounds and the score with reimagined iconic music was perfect.\n",
        "Some of the songs in the movie felt unnecessary but they worked.\n",
        "I think they should've bumped the run time to 105-120 min.\n",
        "90 min felt too short as it goes by quick.\n",
        "I havent had this much wholesome fun at the movies in a long time.\n",
        "If youre a fan you HAVE to see it.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T01:16:04.046673Z",
          "iopub.execute_input": "2023-05-31T01:16:04.046988Z",
          "iopub.status.idle": "2023-05-31T01:16:04.071063Z",
          "shell.execute_reply.started": "2023-05-31T01:16:04.046958Z",
          "shell.execute_reply": "2023-05-31T01:16:04.070065Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I66xCdD06Nbc",
        "outputId": "5d2afd34-3485-4797-f211-5fa886d0ce11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9938808679580688}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is **99% POSITIVE**! *justinvitelli* loves the movie!"
      ],
      "metadata": {
        "id": "mw6RDxiR6Nbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how our model classifies a bad review\n",
        "# this is from 'industriousbug16' (https://www.imdb.com/review/rw8998214)\n",
        "\n",
        "review = \"\"\"\n",
        "Flat, visual noise.\n",
        "Fundamentally incurious. Potentially injurious.\n",
        "The mystique generated by the characters in the games is here raked over and presented\n",
        "haphazardly by hacks.\n",
        "A hobbled attempt to explain a long and random evolution of characters who were never meant\n",
        "to be narratised fails.\n",
        "Doing it well is near impossible when you insist on EVERY LITTLE BIT OF LORE,\n",
        "from the last forty years being shoehorned into 90 minutes.\n",
        "Makes little sense, shamelessly leans on member berries to stimulate older viewers but offers\n",
        "nothing else.\n",
        "I feel sad for the animators who did a sterling job, but to no end as this movie has no soul.\n",
        "\"\"\"\n",
        "sentiment_classifier(review)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-31T01:16:04.072655Z",
          "iopub.execute_input": "2023-05-31T01:16:04.073039Z",
          "iopub.status.idle": "2023-05-31T01:16:04.091868Z",
          "shell.execute_reply.started": "2023-05-31T01:16:04.073000Z",
          "shell.execute_reply": "2023-05-31T01:16:04.090968Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zdT42K86Nbc",
        "outputId": "f08b9fda-e83b-4983-ee7c-97544e18aa15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9951890707015991}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is **99% NEGATIVE**! *industriousbug16* must hate the movie very badly."
      ],
      "metadata": {
        "id": "BYjwORcN6Nbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "### If you would like to use this model without running the entire notebook, try the model at my [HuggingFace](https://huggingface.co/wesleyacheng/movie-review-sentiment-classifier-with-bert).\n",
        "\n",
        "### If you woud like to get this in GitHub, here's my [repo](https://github.com/wesleyacheng/movie-review-sentiment-classifier-with-bert)."
      ],
      "metadata": {
        "id": "77tIkhXi6Nbd"
      }
    }
  ]
}